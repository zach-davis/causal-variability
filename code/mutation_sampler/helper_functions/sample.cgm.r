# Create a sample of size n from a joint. 
# If round = T, the number of each entry type is an integer; else fractions are returned.
# Due to round off, when round = T sampple size is guaranteed to be n. exact = T forces it to be n. 
sample.joint = function (j, n, round = T, exact = F) {
  distance.of.adjusted.entry = function (si) {
    count = s$count; count[si] = count[si] + inc
    p = count / sum (count)
    sum (abs (p - j$p)**2)
  }
  s = j[, joint.vs (j)]; s$count = j$p * n
  if (round) {
    s$count = round (s$count)
    if (exact) {
      # Account for rounding by bumping count for an entry up or down so total is n.
      total = sum (s$count)
      while (total != n) {
        inc = if (total < n) 1 else -1
        ds = sapply (1:nrow (s), distance.of.adjusted.entry)
        si = which (ds == min(ds))[1] # Adjustment that yields the sample most representative of j.
        s[si,]$count = s[si,]$count + inc; total = total + inc
      }
    }  
  }
  s
}

explode.sample = function (s) {
  rep.row = function (r) { rs = r [rep (1, each = r[,"count"]),]; rs$count = 1; rs }
  adply (s [s$count > 0,], .margins = 1, .fun = rep.row)
}

collapse.sample = function (es, with.nas = FALSE) {
  if (with.nas) {
    es.names = interaction.w.nas (es); 
    s = unique (es); s$count = 0; s = sample.with.rownames (s, with.nas = TRUE)
    # For each element in es, update a count in s.
    for (n in es.names) s [n, ]$count = s [n, ]$count + 1
  }
  else {
    s = ddply (es, sample.vs (es), nrow, .drop = FALSE)
    colnames (s)[which (names (s) == "V1")] = "count"
    s = sample.with.rownames (s, with.nas)    
  }
  s
}

sample.subset = function (s, x) {
  joint.subset (s, x)
}

occluded.sample = function (s, visible.vs, occluded.as.nas = F) {
  all.vs = sample.vs (s)
  colnames (s)[ncol (s)] = "p"
  occluded.s = joint.marginalized (s, visible.vs)
  colnames (occluded.s)[ncol (occluded.s)] = "count"
  if (occluded.as.nas) {
    for (v in setdiff (all.vs, visible.vs)) occluded.s[,v] = NA
    occluded.s = occluded.s[,c(all.vs, 'count')]
  }
  else occluded.s = occluded.s[,c(visible.vs, 'count')]
  sample.w.rownames (occluded.s)
}

# The likelihood that the data in sample s was generated by joint distribution j. 
lk.count.p          = function (count, ps, log) if (log) sum (count * log (ps)) else prod (ps ** count)
lk.count.p.binomial = function (count, ps, log) dmultinom.wo.round (count, prob = ps, log = log)
  
sample.lk.driver = function (j, s, lk.fun, with.nas = FALSE, parents = NULL, log = F) {
  lk.conditional = function (px) {
    j = joint.conditionalized (j, px) # Conditionalize the joint on this value of the parents
    sample.lk.driver (j, sample.subset (s, px), lk.fun, log = log) # Recurse
  }
  if (with.nas) stop ('Not implemented')
  stopifnot (all (rownames (s) %in% rownames (j)))
  if (is.null (parents)) {
    # Unconditional case
    lk = do.call (lk.fun, list (s$count, j[rownames(s),]$p, log))
    if (is.na (lk)) { print (j); print (s); stopifnot (!is.na (lk)) }
  }
  else {
    # Conditional case: Compute for each value of the parents.
    lks = apply (xs.of.vs (parents), 1, lk.conditional)
    lk = if (log) sum (lks) else prod (lks)
  }
  lk
}

# The likelihood that the data in sample s was generated by joint distribution j. 
sample.likelihood = function (j, s, with.nas = FALSE, parents = NULL, log = F) {
  sample.lk.driver (j, s, lk.count.p.binomial, with.nas, parents, log = log)
}
sample.loglk = function (j, s, with.nas = FALSE, parents = NULL) {
  sample.lk.driver (j, s, lk.count.p.binomial, with.nas, parents, log = T)
}

# The likelihood that the data in s, treated as a sequence, was generate by joint j. 
sequence.likelihood = function (j, s, with.nas = FALSE, parents = NULL, log = F) {
  sample.lk.driver (j, s, lk.count.p, with.nas, parents, log = log)
}

sequence.loglk = function (j, s, with.nas = FALSE, parents = NULL) {
  sample.lk.driver (j, s, lk.count.p, with.nas, parents, log = T)
}

# The likelihood that the data in sample s was generated by an unparameterized graph (represented 
# by j.fun). Works by sampling over the graph's parameters (defined as the formals of j.fun).
# Range determines the range over which each parameter is sampled. It defaults to 0-1 (i.e., assumes
# that the parameters are probabilities). If range is a list, it is matched one-to-one to each of
# formals of j.fun (thus length (formals (j.fun)) must equal length (range)).
# Parents, if present, define a conditional probability distribution.
# Prior.fun is used to define priors on the parameters (otherwise assumed to be uniformly distributed).
# Lk.fun determies whether the probability of a sample or sequence is computed.
sample.p.range = c (1e-10, 1-1e-10); default.no.ps = 10000
sample.lk.in.parallel = F

# The likelihood of a sample (or sequence, depending on lk.fun) given a graph. 
sample.lk.graph.driver = function (j.fun, lk.fun, s, no.ps = default.no.ps, range = sample.p.range, parents = NULL, prior.fun = NULL, log = F) {
  sample.block = function (no.ps) {
    sampled.ps = function () {
      expand.p.range = function () {
        if (is.list (range)) stopifnot (np == length (range))
        else {
          stopifnot (is.vector (range)) 
          range = rep (list (range), np) 
        } 
        range  
      }
      np = length (formals (j.fun)); range = expand.p.range ()
      ps = array (runif (no.ps * np), dim = c(no.ps, np))
      for (p in 1:np) ps [,p] = range[[p]][1] + ps [,p] * (range[[p]][2] - range[[p]][1])
      ps
    }
    lk.ps = function (ps) do.call (lk.fun, list (do.call (j.fun, as.list (ps)), s, parents = parents))
    ps = sampled.ps ()
    p.s.ps = aaply (ps, 1, lk.ps) # Probability of the sample for each parameter combination. 
    if (is.null (prior.fun)) p.ps = 1 / no.ps
    else {
      p.ps = maply (ps, prior.fun, .expand = F) #### this is where it fails, I think because prior.fun has an ma=0 param but j.fun doesn't have an ma function
      p.ps = p.ps / sum (p.ps) # Normalize
    }
    lk = sum (p.s.ps * p.ps); stopifnot (lk >= 0 & lk <= 1)
    if (log) log (lk) else lk
  } 
  # Distribute sampling over cpus.
  no.ps = rep (round (no.ps / no.cpus), no.cpus)
  #browser()
  mean (laply (as.list (no.ps), sample.block, .parallel = sample.lk.in.parallel))
}

# The (log) likelihood of the sample given a graph. 
sample.likelihood.graph = function (j.fun, s, no.ps = default.no.ps, range = sample.p.range, parents = NULL, prior.fun = NULL) {
  sample.lk.graph.driver (j.fun, sample.likelihood, s, no.ps, range, parents, prior.fun, log = F)
}

sample.loglk.graph = function (j.fun, s, no.ps = default.no.ps, range = sample.p.range, parents = NULL, prior.fun = NULL) {
  sample.lk.graph.driver (j.fun, sample.likelihood, s, no.ps, range, parents, prior.fun, log = T)
}

# The (log) likelihood of a sequence given a graph. 
sequence.likelihood.graph = function (j.fun, s, no.ps = default.no.ps, range = sample.p.range, parents = NULL, prior.fun = NULL) {
  sample.lk.graph.driver (j.fun, sequence.likelihood, s, no.ps, range, parents, prior.fun, log = F)
}

sequence.loglk.graph = function (j.fun, s, no.ps = default.no.ps, range = sample.p.range, parents = NULL, prior.fun = NULL) {
  sample.lk.graph.driver (j.fun, sequence.likelihood, s, no.ps, range, parents, prior.fun, log = T)
}

# How representative of the joint will a sample of size n be.
sample.representativeness = function (j, n, round = T, exact = F) {
  joint.distance (j, sample.to.joint (sample.joint (j, n, round, exact)))
}

# Turn a sample into a joint.
sample.to.joint = function (s) {
  s$count = s$count / sum (s$count)
  colnames (s)[which (names (s) == "count")] = "p"
  s
}

print.sample.stats = function (s, level = 3, zero.assoc = TRUE) {
  j = sample.to.joint (s)
  print.joint.stats (j, level, zero.assoc)
}

# Causal power (unconditional) between two variables.
sample.causal.power = function (s, c, e) {
  vs.causal.power (sample.to.joint (s), c, e)
}  

# Causal power between c and e conditioned on all other variables = 0.
sample.causal.power.0 = function (s, c, e) {
  vs.causal.power.0 (sample.to.joint (s), c, e)
}  

sample.vs = function (s) { 
  n = names (s)
  n[!n %in% c ("count")]  # All column names except for "count"
}

sample.w.rownames = function (s) {
  rownames (s) = interaction.w.nas (s [sample.vs (s)])
  s
}

sample.c2e1.from.counts = function (c11.e1, c11.all, c10.e1, c10.all, c01.e1, c01.all, c00.e1, c00.all) {
  counts = function (c, all) c (all - c, c)
  s = joint.skeleton (c("ca", "cb", "e"))
  s$count = c (counts (c00.e1, c00.all), counts (c01.e1, c01.all), counts (c10.e1, c10.all), counts (c11.e1, c11.all))
  s
}

